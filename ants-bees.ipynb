{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f46e0ab",
   "metadata": {},
   "source": [
    "## <font color='red'>Distinguishing ants from bees</font>\n",
    "\n",
    "This notebook builds a classifier that distinguishes between images of ants and bees. The classifier has three parts to it:\n",
    "- The images are of varying sizes. So first, they are all normalized to a fixed size.\n",
    "- Then they are run through a pre-trained computer vision neural net, ResNet50, that produces a 2048-dimensional representation\n",
    "- Finally, a logistic regression classifier is built on top of this representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a0001",
   "metadata": {},
   "source": [
    "### <font color='red'>Various includes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cbaf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Torch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# Torchvision stuff\n",
    "from torchvision import datasets, models, transforms\n",
    "# sklearn stuff\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a56122",
   "metadata": {},
   "source": [
    "### <font color='red'>Loading Dataset</font>\n",
    "\n",
    "For both the train and test data, the images need to be normalized to the particular size, 224x224x3, that is required by the ResNet50 network that we will apply to them. This is achieved by a series of transforms.\n",
    "\n",
    "- The (normalized) training set is in image_datasets['train']\n",
    "- The (normalized) test set is in image_datasets['val']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27988297",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = '/Users/marlenearredondo/Documents/Masters- Data Science/Winter 2023/255R/Week 9/hymenoptera_data'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed76e16",
   "metadata": {},
   "source": [
    "#### <font color='red'>Look at the classes and data set sizes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7a0f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ants', 'bees']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b260d60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 244, 'val': 153}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a387325",
   "metadata": {},
   "source": [
    "#### <font color='red'>Print a sample (transformed) image</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ebfdeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rp/mtyztnnd6p35kq9b5_xbdn7c0000gn/T/ipykernel_82132/2790633549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m244\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mitemx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitemy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Label: {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitemy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mclass_index\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "item = 244\n",
    "[itemx,itemy] = image_datasets['train'].__getitem__(item)\n",
    "print(\"Label: {}\\n\".format(class_names[itemy]))\n",
    "plt.imshow(itemx.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eabfd1d",
   "metadata": {},
   "source": [
    "### <font color='red'>Load pre-trained ResNet50</font>\n",
    "\n",
    "Torch has a bunch of pre-trained nets for computer vision. Let's try out one of them: ResNet50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60948277",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained = True)\n",
    "modules = list(resnet50.children())[:-1]\n",
    "resnet50 = nn.Sequential(*modules)\n",
    "for p in resnet50.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed5b88",
   "metadata": {},
   "source": [
    "### <font color='red'>Extract ResNet features from dataset</font>\n",
    "\n",
    "We'll use ResNet to produce a 2048-dimensional representation for each image.\n",
    "\n",
    "The resulting training set will be in the Numpy arrays (X_train, y_train) and the test set will be in the Numpy arrays (X_test, y_test).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f33ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x])\n",
    "              for x in ['train', 'val']}\n",
    "for batch,data in enumerate(dataloaders['train']):\n",
    "    if batch==0:\n",
    "        X_train = torch.squeeze(resnet50(data[0])).numpy()\n",
    "        y_train = data[1].numpy()\n",
    "    else:\n",
    "        X_train = np.vstack((X_train,torch.squeeze(resnet50(data[0])).numpy()))\n",
    "        y_train = np.hstack((y_train,data[1].numpy()))\n",
    "\n",
    "\n",
    "for batch,data in enumerate(dataloaders['val']):\n",
    "    if batch==0:\n",
    "        X_test = torch.squeeze(resnet50(data[0])).numpy()\n",
    "        y_test = data[1].numpy()\n",
    "    else:\n",
    "        X_test = np.vstack((X_test,torch.squeeze(resnet50(data[0])).numpy()))\n",
    "        y_test = np.hstack((y_test,data[1].numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3a1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1f6d4",
   "metadata": {},
   "source": [
    "### <font color='red'>Train logistic regression classifier on the ResNet features</font>\n",
    "\n",
    "And then we'll evaluate its performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d38f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear',random_state=0,max_iter=1000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c249b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy: {}\\n\".format(accuracy_score(y_test,y_pred)))\n",
    "print(\"Confusion matrix: \\n {}\".format(confusion_matrix(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5000a796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
