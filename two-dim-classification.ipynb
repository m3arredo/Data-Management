{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Includes and network parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network parameters\n",
    "'''\n",
    "num_neurons : TYPE list\n",
    "            DESCRIPTION. list of neurons in each layer.\n",
    "                This should have a minimum length of 3. \n",
    "                First element represents the dimension of input vector.\n",
    "                Last element represents the dimension of the output vector.\n",
    "                middle elements represent the number of neurons in hidden layers.\n",
    "activations : TYPE, option list where each element can be either 'relu' or 'sigmoid' or 'tanh'\n",
    "            DESCRIPTION. The default is ['relu'].\n",
    "            If len(activations)==1: \n",
    "                same activation function is applied across all hidden layers.\n",
    "            else:\n",
    "                len(activations) should be equal to the number of hidden layers.\n",
    "'''\n",
    "num_neurons = [2,20,10,10,2] # list of neurons in each layer of NN. \n",
    "activations = ['relu'] # represents the activation function used at the hidden layers.\n",
    "\n",
    "# optimizer parameters\n",
    "lr = 0.01\n",
    "lr_step = [500]\n",
    "weight_decay = 1e-3\n",
    "\n",
    "#  training parameters\n",
    "num_epochs = 200\n",
    "batch_size = 256\n",
    "\n",
    "# \n",
    "print_freq = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Create and plot data set</font>\n",
    "\n",
    "Do not change this cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT change this cell.\n",
    "ns = 800\n",
    "np.random.seed(0)\n",
    "X_train = np.random.rand(ns,2)\n",
    "x1 = X_train[:,0]\n",
    "x2 = X_train[:,1]\n",
    "y_train = ((np.exp(-((x1-0.5)*6)**2)*2*((x1-0.5)*6)+1)/2-x2)>0 \n",
    "\n",
    "idx = np.random.choice(range(ns),size=(int(ns*0.03),))\n",
    "y_train[idx] = ~y_train[idx]\n",
    "\n",
    "ns = 300\n",
    "np.random.seed(1)\n",
    "X_val = np.random.rand(ns,2)\n",
    "x1 = X_val[:,0]\n",
    "x2 = X_val[:,1]\n",
    "y_val = ((np.exp(-((x1-0.5)*6)**2)*2*((x1-0.5)*6)+1)/2-x2)>0 \n",
    "\n",
    "def plot(X,y,title=\"Dataset\"):\n",
    "    colors = np.where(y==0, 'r', 'b')\n",
    "    plt.figure()\n",
    "    plt.scatter(X[:,0],X[:,1],color=colors)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot(X_train,y_train,\"Train dataset\")\n",
    "plot(X_val,y_val,\"Test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Load data set into Torch dataloader</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.Tensor(X_train) # transform to torch tensor\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor,y_train_tensor) # create your datset\n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True,drop_last=False)\n",
    "\n",
    "X_val_tensor = torch.Tensor(X_val) # transform to torch tensor\n",
    "y_val_tensor = torch.Tensor(y_val)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor,y_val_tensor) # create your datset\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_size,shuffle=True,drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Model: Feedforward neural network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_neurons,activations=['relu']):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_neurons : TYPE list\n",
    "            DESCRIPTION. list of neurons in each layer.\n",
    "                This should have a minimum length of 3. \n",
    "                First element represents the dimension of input vector.\n",
    "                Last element represents the dimension of the output vector.\n",
    "                middle elements represent the number of neurons in hidden layers.\n",
    "            \n",
    "        activations : TYPE, optional list.\n",
    "            DESCRIPTION. The default is ['relu'].\n",
    "            If len(activations)==1: \n",
    "                same activation function is applied across all hidden layers.\n",
    "            else:\n",
    "                len(actiavtions) should be equal to the number of hidden layers.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        \n",
    "        super(LinearNN,self).__init__()\n",
    "        assert isinstance(num_neurons,list)\n",
    "        assert np.all([isinstance(neurons,int) for neurons in num_neurons])\n",
    "        assert np.all([neurons>=1 for neurons in num_neurons])\n",
    "        assert len(num_neurons)>=3 \n",
    "        if activations is not None:\n",
    "            assert isinstance(activations,(list))\n",
    "            assert (len(activations)==len(num_neurons)-2) or (len(activations)==1)\n",
    "        \n",
    "        \n",
    "        def activation_layer(act_func):\n",
    "            '''\n",
    "            \n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            act_func : TYPE should be one from {'relu','sigmoid','tanh'}.\n",
    "                DESCRIPTION.\n",
    "\n",
    "            Raises\n",
    "            ------\n",
    "            NotImplementedError\n",
    "                DESCRIPTION.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            TYPE\n",
    "                DESCRIPTION.\n",
    "\n",
    "            '''\n",
    "            if act_func=='relu':\n",
    "                return nn.ReLU(inplace=True)\n",
    "            elif act_func=='sigmoid':\n",
    "                return nn.Sigmoid()\n",
    "            elif act_func=='tanh':\n",
    "                return nn.Tanh()\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "                \n",
    "        \n",
    "        layers = []\n",
    "        for idx,_ in enumerate(num_neurons[:-1]):\n",
    "            layers.append(nn.Linear(in_features=num_neurons[idx],\n",
    "                                    out_features=num_neurons[idx+1],\n",
    "                                    bias=True))\n",
    "            \n",
    "            if idx!=len(num_neurons)-2: # add activation for all layers except the last layer.\n",
    "                if len(activations)==1:\n",
    "                    layers.append(activation_layer(activations[0]))\n",
    "                else:\n",
    "                    layers.append(activation_layer(activations[idx]))\n",
    "                \n",
    "        self.network = nn.Sequential(*layers)\n",
    "            \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def linear_nn(num_neurons,activations=['relu']):\n",
    "    model = LinearNN(num_neurons,activations)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Define training function</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.to(device)\n",
    "        input_var = torch.autograd.Variable(input).to(device)\n",
    "        target_var = torch.autograd.Variable(target).to(device)\n",
    "        # target_var = torch.squeeze(target_var)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = criterion(output, target_var.long())\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1[0][0], input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            curr_lr = optimizer.param_groups[0]['lr']\n",
    "            print('Epoch: [{0}/{1}][{2}/{3}]\\t'\n",
    "                  'LR: {4}\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Train Acc {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                   epoch, num_epochs, i, len(train_loader), curr_lr,\n",
    "                   loss=losses, top1=top1))\n",
    "\n",
    "\n",
    "    print(' * Train Acc {top1.avg:.3f}'.format(top1=top1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Define validation and prediction functions</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.to(device)\n",
    "        input_var = torch.autograd.Variable(input, volatile=True).to(device)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True).to(device)\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        # loss = criterion(output, target_var[:,None])\n",
    "        loss = criterion(output, target_var.long())\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1[0][0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                   i, len(val_loader), loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "\n",
    "    print(' * Test Acc {top1.avg:.3f}'.format(top1=top1))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def predict(dataloader,model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    x = []\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(dataloader):\n",
    "            # target = target.to(device)\n",
    "            input_var = torch.autograd.Variable(input, volatile=True).to(device)\n",
    "            # target_var = torch.autograd.Variable(target, volatile=True).to(device)\n",
    "    \n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            labels = torch.argmax(output,axis=1)\n",
    "            y_pred.extend(list(labels.data.detach().cpu().numpy()))\n",
    "            y_true.extend(list(target.numpy()))\n",
    "            x.extend(list(input_var.data.detach().cpu().numpy()))\n",
    "    return np.array(x),np.array(y_true),np.array(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Function to plot the decision boundary of the neural network</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model):\n",
    "    h = 0.005\n",
    "    x_min, x_max = 0,1\n",
    "    y_min, y_max = 0,1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    x1 = xx.ravel()\n",
    "    x2 = yy.ravel()\n",
    "    y = ((np.exp(-((x1-0.5)*6)**2)*2*((x1-0.5)*6)+1)/2-x2)>0 \n",
    "    \n",
    "    X_train_tensor = torch.Tensor(np.c_[xx.ravel(), yy.ravel()]) # transform to torch tensor\n",
    "    y_train_tensor = torch.Tensor(y)\n",
    "    \n",
    "    dataset = TensorDataset(X_train_tensor,y_train_tensor) # create your datset\n",
    "    dataloader = DataLoader(dataset,batch_size=batch_size,shuffle=False,drop_last=False)\n",
    "\n",
    "    \n",
    "    x,y_true,y_pred = predict(dataloader,model)\n",
    "    Z = y_pred.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.contourf(x[:,0].reshape(xx.shape), x[:,1].reshape(xx.shape), Z, cmap=plt.cm.Paired)\n",
    "    plt.axis('tight')\n",
    "    \n",
    "    # scatter plot of data points with colors corresponding to the correct labels. \n",
    "    ns = 500\n",
    "    np.random.seed(0)\n",
    "    X_test = np.random.rand(ns,2)\n",
    "    x1 = X_test[:,0]\n",
    "    x2 = X_test[:,1]\n",
    "    y_test = ((np.exp(-((x1-0.5)*6)**2)*2*((x1-0.5)*6)+1)/2-x2)>0 \n",
    "    colors = np.where(y_test==0, 'r', 'b')\n",
    "    plt.scatter(x1,x2,color=colors)\n",
    "    # plt.scatter(x[:,0],x[:,1],colors=)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Functions to track the model performance and save the desired model state</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Create model instance; define loss function and optimizer</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(999)\n",
    "model = linear_nn(num_neurons,activations).to(device)\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device) \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Train model and validate</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prec1 = 0\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch in lr_step:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] *= 0.1\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    # prec1 = 0\n",
    "    prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec1': best_prec1,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best,filename=\"checkpoint.pth.tar\")\n",
    "    print(\"-----------------------------------------------\")\n",
    "    \n",
    "    if epoch%print_freq==0:\n",
    "        plot_decision_boundary(model)\n",
    "\n",
    "plot_decision_boundary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
